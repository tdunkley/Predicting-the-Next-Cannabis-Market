{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:39:22.689583Z",
     "start_time": "2019-12-21T22:39:17.878106Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "#import ydata profiling\n",
    "from ydata_profiling import ProfileReport\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:39:26.092575Z",
     "start_time": "2019-12-21T22:39:23.574792Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import religion and election excel file:\n",
    "\n",
    "df_rv = pd.read_excel('ReligionData.xlsx',sheet_name='Religion and Election Data')\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_rv = df_rv.fillna(0)\n",
    "\n",
    "# remove columns:\n",
    "\n",
    "df_rv = df_rv[df_rv.columns.drop(list(df_rv.filter(regex='per Thousand')))]\n",
    "df_rv = df_rv[df_rv.columns.drop(list(df_rv.filter(regex='Per Thousand')))]\n",
    "df_rv = df_rv[df_rv.columns.drop(list(df_rv.filter(regex='Buddhism')))]\n",
    "df_rv = df_rv.drop([\n",
    "'Indian-American Hindu Adherents',\n",
    "'Post Renaissance Hindu Adherents',\n",
    "'Renaissance Hindu Adherents',\n",
    "'Traditional Hindu Temples Adherents',\n",
    "'Conservative Judaism Adherents',\n",
    "'Orthodox Judaism Adherents',\n",
    "'Reconstructionist Judaism Adherents',\n",
    "'Reform Judaism Adherents'], axis=1)\n",
    "\n",
    "# create state mapping dictionary:\n",
    "\n",
    "us_state_abbrev = {\n",
    "    'AL': 'Alabama',\n",
    "    'AK': 'Alaska',\n",
    "    'AZ': 'Arizona',\n",
    "    'AR': 'Arkansas',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DC': 'District of Columbia',\n",
    "    'DE': 'Delaware',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'HI': 'Hawaii',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'IA': 'Iowa',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'ME': 'Maine',\n",
    "    'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MS': 'Mississippi',\n",
    "    'MO': 'Missouri',\n",
    "    'MT': 'Montana',\n",
    "    'NE': 'Nebraska',\n",
    "    'NV': 'Nevada',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NY': 'New York',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VT': 'Vermont',\n",
    "    'VA': 'Virginia',\n",
    "    'WA': 'Washington',\n",
    "    'WV': 'West Virginia',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WY': 'Wyoming',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:39:27.517733Z",
     "start_time": "2019-12-21T22:39:27.446932Z"
    }
   },
   "outputs": [],
   "source": [
    "# make updates to df_rv dataframe:\n",
    "\n",
    "df_rv['State Code'] = df_rv.replace({'State Code':us_state_abbrev})  # update State Code with full state name\n",
    "df_rv['County Name'] = df_rv['County Name'].map(str) + ', ' + df_rv['State Code'].map(str) # concatenate county and state\n",
    "\n",
    "# rename df_rv columns:\n",
    "\n",
    "df_rv.rename(columns={'Clinton or Trump State':'Party Affiliation',\n",
    "                     'Clinton':'Democrat','Trump':'Republican',\n",
    "                     '% Clinton':'% Democrat','% Trump':'% Republican',\n",
    "                     'County Name':'Geographic Area Name',\n",
    "                     'State Code':'State_Code'}, inplace=True)\n",
    "\n",
    "# update Party Affiliation:\n",
    "\n",
    "df_rv['Party Affiliation'] = df_rv['Party Affiliation'].replace({'Trump':'Republican','Clinton':'Democrat'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T14:49:04.703968Z",
     "start_time": "2019-12-20T14:49:04.688852Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "https://youtu.be/Px3_lDaXHJM    # df_rv.head()\n",
    "# print(df_rv.info())\n",
    "\n",
    "# print(df_dem.info()) # Geographic Area Name 838 non-null object\n",
    "# df_dem['Geographic Area Name'].unique\n",
    "\n",
    "df_rv['Geographic Area Name'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T15:11:21.264171Z",
     "start_time": "2019-12-21T15:11:21.243229Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_rv.dtypes)\n",
    "    \n",
    "chk = df_rv.select_dtypes(include ='object')\n",
    "chk.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T14:49:12.382153Z",
     "start_time": "2019-12-20T14:49:12.366312Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T14:49:16.635828Z",
     "start_time": "2019-12-20T14:49:16.542035Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rv[df_rv['State_Code']=='Alabama']\n",
    "# df_rv['Party Affiliation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:39:42.517828Z",
     "start_time": "2019-12-21T22:39:42.089799Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import demographic and housing estimates csv:\n",
    "\n",
    "df_dem = pd.read_csv('2018 ACS DP05 Demographic and Housing Estimates.csv',header=1)\n",
    "df_dem = df_dem[df_dem.columns.drop(list(df_dem.filter(regex='Margin of Error!!')))]  # drop columns with MoE\n",
    "df_dem = df_dem[df_dem.columns.drop(list(df_dem.filter(regex='Percent Estimate!!')))] # drop columns with PctEst\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_dem = df_dem.fillna(0) # update nan columns with zero\n",
    "\n",
    "\n",
    "# replace invalid values:\n",
    "\n",
    "c = df_dem.columns[2:]\n",
    "for x in c:\n",
    "    df_dem[x].replace('N',0,inplace=True)\n",
    "    df_dem[x].replace('(X)',0,inplace=True)\n",
    "    df_dem[x].replace('None',0,inplace=True)\n",
    "\n",
    "# change data types:\n",
    "\n",
    "c = df_dem.columns[35:]\n",
    "for x in c:\n",
    "    df_dem[x] = df_dem[x].astype(int)\n",
    "\n",
    "# df_dem.apply(pd.to_numeric, errors='ignore')\n",
    "    \n",
    "df_dem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:40:08.431831Z",
     "start_time": "2019-12-21T22:40:08.402958Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check to see if there are any df_dem objects:\n",
    "\n",
    "print(df_dem.dtypes)\n",
    "    \n",
    "chk1 = df_dem.select_dtypes(include ='object')\n",
    "chk1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:39:54.154785Z",
     "start_time": "2019-12-21T22:39:53.497445Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import housing characteristics csv:\n",
    "\n",
    "df_hou = pd.read_csv('2018 ACS DP04 Housing Characteristics.csv',header=1)\n",
    "df_hou = df_hou[df_hou.columns.drop(list(df_hou.filter(regex='Margin of Error!!')))]\n",
    "df_hou = df_hou[df_hou.columns.drop(list(df_hou.filter(regex='Percent Estimate!!')))]\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_hou = df_hou.fillna(0)\n",
    "\n",
    "# replace invalid values:\n",
    "\n",
    "c = df_hou.columns[2:]\n",
    "for x in c:\n",
    "    df_hou[x].replace('N',0,inplace=True)\n",
    "    df_hou[x].replace('(X)',0,inplace=True)\n",
    "    df_hou[x].replace('None',0,inplace=True)\n",
    "    \n",
    "    \n",
    "df_hou['Estimate!!HOUSING OCCUPANCY!!Total housing units!!Homeowner vacancy rate'] = df_hou['Estimate!!HOUSING OCCUPANCY!!Total housing units!!Homeowner vacancy rate'].astype(float)\n",
    "\n",
    "df_hou['Estimate!!HOUSING OCCUPANCY!!Total housing units!!Rental vacancy rate'] = df_hou['Estimate!!HOUSING OCCUPANCY!!Total housing units!!Rental vacancy rate'].astype(float)\n",
    "\n",
    "# change data types for df_hou objects:\n",
    "\n",
    "c1 = df_hou.select_dtypes(include ='object')\n",
    "c1.columns[2:]\n",
    "\n",
    "\n",
    "# change data types to int\n",
    "c = c1.columns[2:]\n",
    "for x in c:\n",
    "    df_hou[x] = df_hou[x].astype(int)\n",
    "    \n",
    "df_hou.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:40:16.617004Z",
     "start_time": "2019-12-21T22:40:16.574084Z"
    }
   },
   "outputs": [],
   "source": [
    "# check to see if data type modification took place:\n",
    "\n",
    "print(df_hou.dtypes)\n",
    "\n",
    "chk2 = df_hou.select_dtypes(include ='object')\n",
    "chk2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T14:50:18.888461Z",
     "start_time": "2019-12-20T14:50:18.873384Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df_hou.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T07:37:09.263428Z",
     "start_time": "2019-12-20T07:37:09.251616Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# c1.columns[4:]\n",
    "# c1.columns[2:4]\n",
    "# df_hou.select_dtypes(include ='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:40:24.887200Z",
     "start_time": "2019-12-21T22:40:24.267389Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import economic charateristics csv:\n",
    "\n",
    "df_econ = pd.read_csv('2018 ACS DP03 Economic Characteristics.csv',header=1)\n",
    "df_econ = df_econ[df_econ.columns.drop(list(df_econ.filter(regex='Margin of Error!!')))]\n",
    "df_econ = df_econ[df_econ.columns.drop(list(df_econ.filter(regex='Percent Estimate!!')))]\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_econ = df_econ.fillna(0)\n",
    "\n",
    "# replace invalid values:\n",
    "\n",
    "c = df_econ.columns[2:]\n",
    "for x in c:\n",
    "    df_econ[x].replace('N',0,inplace=True)\n",
    "    df_econ[x].replace('(X)',0,inplace=True)\n",
    "    df_econ[x].replace('None',0,inplace=True)\n",
    "    \n",
    "    \n",
    "# change data types for df_hou objects:\n",
    "\n",
    "c1 = df_econ.select_dtypes(include ='object')\n",
    "c1.columns[2:]\n",
    "\n",
    "\n",
    "# # change data types to float\n",
    "# c = c1.columns[2:4]\n",
    "# for x in c:\n",
    "#     df_econ[x] = df_econ[x].astype(float)\n",
    "\n",
    "    \n",
    "# change data types to int\n",
    "c = c1.columns[2:]\n",
    "for x in c:\n",
    "    df_econ[x] = df_econ[x].astype(int)\n",
    "    \n",
    "df_econ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:40:28.040350Z",
     "start_time": "2019-12-21T22:40:27.989387Z"
    }
   },
   "outputs": [],
   "source": [
    "chk3 = df_econ.select_dtypes(include ='object')\n",
    "chk3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:40:32.121109Z",
     "start_time": "2019-12-21T22:40:31.401503Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import social characteristics csv:\n",
    "\n",
    "df_soc = pd.read_csv('2018 ACS DP02 Social Characteristics.csv',header=1)\n",
    "df_soc = df_soc[df_soc.columns.drop(list(df_soc.filter(regex='Margin of Error!!')))]\n",
    "df_soc = df_soc[df_soc.columns.drop(list(df_soc.filter(regex='Percent Estimate!!')))]\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_soc = df_soc.fillna(0)\n",
    "\n",
    "# replace invalid values:\n",
    "\n",
    "c = df_soc.columns[2:]\n",
    "for x in c:\n",
    "    df_soc[x].replace('N',0,inplace=True)\n",
    "    df_soc[x].replace('(X)',0,inplace=True)\n",
    "    df_soc[x].replace('None',0,inplace=True)\n",
    "    \n",
    "c1 = df_soc.select_dtypes(include ='object')\n",
    "c1.columns[2:]\n",
    "\n",
    "\n",
    "# # change data types to float\n",
    "# c = c1.columns[2:4]\n",
    "# for x in c:\n",
    "#     df_econ[x] = df_econ[x].astype(float)\n",
    "\n",
    "    \n",
    "# change data types to int\n",
    "c = c1.columns[2:]\n",
    "for x in c:\n",
    "    df_soc[x] = df_soc[x].astype(int)\n",
    "    \n",
    "df_soc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:40:41.852359Z",
     "start_time": "2019-12-21T22:40:41.811402Z"
    }
   },
   "outputs": [],
   "source": [
    "df_soc.dtypes\n",
    "chk4 = df_soc.select_dtypes(include ='object')\n",
    "chk4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T02:19:03.280163Z",
     "start_time": "2019-12-22T02:19:02.065394Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scrape legalization status by state:\n",
    "\n",
    "url = \"https://disa.com/map-of-marijuana-legality-by-state\"\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "# use getText()to extract the text we need into a list:\n",
    "headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
    "    \n",
    "    \n",
    "# avoid the first header row:\n",
    "rows = soup.findAll('tr')[1:]\n",
    "\n",
    "r = [[td.getText() for td in rows[i].findAll('td')]\n",
    "            for i in range(len(rows))]\n",
    "\n",
    "\n",
    "state_laws = pd.DataFrame(r, columns = headers)\n",
    "state_laws = state_laws.drop(columns='State Laws')\n",
    "\n",
    "\n",
    "# remove asterisks from multiple column values:\n",
    "\n",
    "for x in state_laws.columns[1:]:\n",
    "    state_laws[x].replace(regex=[\"\\*\"],value='',inplace=True)\n",
    "\n",
    "\n",
    "state_laws.rename(columns={'State':'State_Code'}, inplace=True)\n",
    "state_laws.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T14:46:19.191858Z",
     "start_time": "2019-12-21T14:46:19.089823Z"
    }
   },
   "outputs": [],
   "source": [
    "# import PRRI excel file:\n",
    "\n",
    "df_prri = pd.read_excel('PRRI_Religion.xlsx',sheet_name='Sheet 1',header=2)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_prri = df_prri.fillna(0)\n",
    "df_prri = df_prri.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T14:46:21.635568Z",
     "start_time": "2019-12-21T14:46:21.607087Z"
    }
   },
   "outputs": [],
   "source": [
    "# check df_prri:\n",
    "\n",
    "df_prri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:40:58.855483Z",
     "start_time": "2019-12-21T22:40:58.813568Z"
    }
   },
   "outputs": [],
   "source": [
    "# create merged dataframe:\n",
    "\n",
    "df_merge = pd.merge(df_dem, df_hou, on=['id', 'Geographic Area Name'])\n",
    "df_merge = pd.merge(df_merge, df_econ, on=['id', 'Geographic Area Name'])\n",
    "df_merge = pd.merge(df_merge, df_soc, on=['id', 'Geographic Area Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T08:59:38.343305Z",
     "start_time": "2019-12-20T08:59:38.311129Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_merge.info()\n",
    "print(len(df_merge['Geographic Area Name']))\n",
    "# df_merge['Geographic Area Name'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:41:09.073355Z",
     "start_time": "2019-12-21T22:41:09.064926Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# assign state to dataframe:\n",
    "\n",
    "w = []\n",
    "for x in df_merge['Geographic Area Name']:\n",
    "#     w.append(re.split(r',',x))\n",
    "    splitting = x.split(',')\n",
    "    last = splitting[1]\n",
    "    l = last.strip()\n",
    "    w.append(l)\n",
    "\n",
    "df_merge['State_Code'] = w\n",
    "\n",
    "# replace name of NM county:\n",
    "\n",
    "df_merge['Geographic Area Name'].replace('Doña Ana County, New Mexico','Dona Ana County, New Mexico',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:41:16.675082Z",
     "start_time": "2019-12-21T22:41:16.650384Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check df_merge:\n",
    "pd.set_option('display.max_rows', 10)\n",
    "df_merge.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:42:01.080461Z",
     "start_time": "2019-12-21T22:41:59.878016Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.merge(df_merge, df_rv, on= ['Geographic Area Name'],how='left')\n",
    "df1.drop(columns=(['State_Code_y']),inplace = True)\n",
    "df1.rename(columns={'State_Code_x':'State_Code'}, inplace=True)\n",
    "\n",
    "c = df1.columns[1:]\n",
    "for x in c:\n",
    "    df1[x].replace('!','',inplace=True)\n",
    "    df1[x].replace('\"','',inplace=True)\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:43:20.001142Z",
     "start_time": "2019-12-21T22:43:19.852816Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df_merge.dtypes)\n",
    "    \n",
    "chk5 = df_merge.select_dtypes(include ='object')\n",
    "chk5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:44:21.316927Z",
     "start_time": "2019-12-21T22:44:20.904981Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df1, state_laws, on= ['State_Code'])\n",
    "df.head()\n",
    "\n",
    "# print(state_laws.dtypes)\n",
    "# df1.dtypes\n",
    "\n",
    "# print(df1['State_Code'].unique())\n",
    "# print(state_laws['State_Code'].unique())\n",
    "\n",
    "# df.drop(columns=(['State Code_y']),inplace = True)\n",
    "# df.rename(columns={'State Code_x':'State Code'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T16:46:08.365685Z",
     "start_time": "2019-12-20T16:46:08.123577Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(\n",
    "df_dem.info())\n",
    "# [838 rows x 91 columns]>\n",
    "\n",
    "df_hou.info()\n",
    "# [838 rows x 145 columns]>\n",
    "\n",
    "display(\n",
    "df_econ.info())\n",
    "# [838 rows x 139 columns]>\n",
    "\n",
    "df_soc.info()\n",
    "# [838 rows x 154 columns]>\n",
    "\n",
    "display(\n",
    "df_merge.info())\n",
    "# [838 rows x 523 columns]>\n",
    "\n",
    "df_rv.info()\n",
    "# [3113 rows x 55 columns]>\n",
    "\n",
    "\n",
    "display(df.info())\n",
    "# Int64Index: 823 entries, 0 to 822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T14:52:03.814065Z",
     "start_time": "2019-12-21T14:52:03.783109Z"
    }
   },
   "outputs": [],
   "source": [
    "unique = df_merge['Geographic Area Name'].unique()\n",
    "for x in unique:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T14:52:38.760718Z",
     "start_time": "2019-12-21T14:52:38.711378Z"
    }
   },
   "outputs": [],
   "source": [
    "unique = df['Geographic Area Name'].unique()\n",
    "for x in unique:\n",
    "    print(x)\n",
    "    \n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:46:12.120767Z",
     "start_time": "2019-12-21T22:46:11.604762Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace column characters:\n",
    "\n",
    "df.columns= df.columns.str.replace('!','',regex=True)  # replace exclamation marks\n",
    "df.columns= df.columns.str.replace('$','',regex=True)  # replace dollar signs\n",
    "df.columns= df.columns.str.replace(\"'\",'',regex=True)  # replace apostrophes\n",
    "df.columns= df.columns.str.replace(',','',regex=True)  # replace commas\n",
    "df.columns= df.columns.str.replace('.','',regex=True)  # replace periods\n",
    "df.columns= df.columns.str.replace('\"','',regex=True)  # replace quotes \n",
    "df.columns = df.columns.str.replace('-', '_',regex=True)  # replace dashes with underscores\n",
    "df.columns = df.columns.str.replace('(', '',regex=True)  # replace open parentheses\n",
    "df.columns = df.columns.str.replace(')', '',regex=True)  # replace close parentheses\n",
    "df.columns = df.columns.str.replace('%', 'Pct',regex=True)  # replace percentage sign\n",
    "df.columns = df.columns.str.replace(' ', '',regex=True)  # replace white space in columns\n",
    "\n",
    "# replace null values in dataframe:\n",
    "\n",
    "df.fillna(0,inplace=True)\n",
    "\n",
    "# update Alaska Party Affiliation:\n",
    "\n",
    "df['PartyAffiliation'].replace(regex=[0],value='Republican',inplace=True)\n",
    "\n",
    "# replace None values in dataframe:\n",
    "\n",
    "c = df.columns[1:]\n",
    "for x in c:\n",
    "    df[x].replace('None',0,inplace=True)\n",
    "\n",
    "for x in c:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:46:24.088898Z",
     "start_time": "2019-12-21T22:46:24.059013Z"
    }
   },
   "outputs": [],
   "source": [
    "# use function to check for missing values:\n",
    "\n",
    "def missing_values_table(df):\n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        return mis_val_table_ren_columns\n",
    "    \n",
    "missing_values_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T23:46:52.682563Z",
     "start_time": "2019-12-21T22:53:05.142223Z"
    }
   },
   "outputs": [],
   "source": [
    "# execute pandas profiling on df dataframe:\n",
    "\n",
    "profile = df.profile_report()\n",
    "rejected_variables = profile.get_rejected_variables(threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T23:54:22.043525Z",
     "start_time": "2019-12-21T23:54:22.029417Z"
    }
   },
   "outputs": [],
   "source": [
    "rejected_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T23:56:23.659439Z",
     "start_time": "2019-12-21T23:56:23.528540Z"
    }
   },
   "outputs": [],
   "source": [
    "# inspect the objects for columns needed:\n",
    "\n",
    "chk6 = df.select_dtypes(include ='object')\n",
    "chk6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T15:13:40.017758Z",
     "start_time": "2019-12-23T15:13:40.013382Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop unnecessary categories:\n",
    "\n",
    "p = ['id','ANSICode', 'CBSATitle', 'Metropolitan/MicropolitanStatisticalArea',\n",
    "       'CSATitle', 'MetropolitanDivisionTitle', 'Central/OutlyingCounty']\n",
    "\n",
    "for x in p:\n",
    "    df.drop([x],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T00:03:13.471232Z",
     "start_time": "2019-12-22T00:03:12.744703Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop rejected variables from pandas profiling:\n",
    "\n",
    "for x in rejected_variables:\n",
    "    df.drop([x],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T02:43:30.981783Z",
     "start_time": "2019-12-22T02:39:05.032346Z"
    }
   },
   "outputs": [],
   "source": [
    "# execute pandas profiling again:\n",
    "\n",
    "profile = df.profile_report()\n",
    "rejected_variables = profile.get_rejected_variables(threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T02:44:37.061247Z",
     "start_time": "2019-12-22T02:44:36.188511Z"
    }
   },
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T14:45:17.671425Z",
     "start_time": "2019-12-23T14:45:17.572740Z"
    }
   },
   "outputs": [],
   "source": [
    "# check Party Affiliation for zeros:\n",
    "\n",
    "df[df['PartyAffiliation']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T14:54:02.484944Z",
     "start_time": "2019-12-21T14:54:02.082220Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.Zoroastrian_Adherents.unique()\n",
    "c = df.columns[1:]\n",
    "for x in c:\n",
    "    df[x].replace('None',0,inplace=True)\n",
    "#     df[x].fillna(value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T17:38:33.187147Z",
     "start_time": "2019-12-19T17:38:33.141458Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "# df_rv['County Name'].unique\n",
    "df_dem['Geographic Area Name'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T14:45:38.312397Z",
     "start_time": "2019-12-23T14:45:38.151402Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()\n",
    "c = df.columns[0:]\n",
    "\n",
    "for x in c:\n",
    "    print(x)\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T14:54:48.732654Z",
     "start_time": "2019-12-23T14:54:45.730194Z"
    }
   },
   "outputs": [],
   "source": [
    "from pivottablejs import pivot_ui\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import seaborn as sns \n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-26T21:21:27.573994Z",
     "start_time": "2019-12-26T21:21:27.113202Z"
    }
   },
   "outputs": [],
   "source": [
    "# check legalized distribution:\n",
    "\n",
    "user_rating = df['Legalized'].value_counts()\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.xlabel(\"Legal Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Legalized Distribution\")\n",
    "sns.barplot(user_rating.index, user_rating.values, palette='bright');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T15:02:14.877091Z",
     "start_time": "2019-12-23T15:02:14.573973Z"
    }
   },
   "outputs": [],
   "source": [
    "# check legal status distribution:\n",
    "\n",
    "user_rating = df['LegalStatus'].value_counts()\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.xlabel(\"Legal Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Legal Status Distribution\")\n",
    "sns.barplot(user_rating.index, user_rating.values, palette='bright');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T21:27:12.483406Z",
     "start_time": "2019-12-23T21:27:12.466398Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df['LegalStatus'].value_counts())\n",
    "df_copy['LegalStatus'].value_counts()\n",
    "# df_copy[df_copy['LegalStatus']=='Fully Legal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T14:57:44.664080Z",
     "start_time": "2019-12-23T14:57:44.358985Z"
    }
   },
   "outputs": [],
   "source": [
    "# check party affiliation distribution:\n",
    "\n",
    "user_rating = df['PartyAffiliation'].value_counts()\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.xlabel(\"Party Affiliation\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Political Party Distribution\")\n",
    "sns.barplot(user_rating.index, user_rating.values, palette='bright');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T15:00:13.080241Z",
     "start_time": "2019-12-23T15:00:12.792397Z"
    }
   },
   "outputs": [],
   "source": [
    "# check medicinal distribution:\n",
    "\n",
    "user_rating = df['Medicinal'].value_counts()\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.xlabel(\"Medicinal Values\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Medicinal Distribution\")\n",
    "sns.barplot(user_rating.index, user_rating.values, palette='bright');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T15:01:17.636567Z",
     "start_time": "2019-12-23T15:01:17.348990Z"
    }
   },
   "outputs": [],
   "source": [
    "# check decriminalized distribution:\n",
    "\n",
    "user_rating = df['Decriminalized'].value_counts()\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.xlabel(\"Decriminalized Values\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Decriminalized Distribution\")\n",
    "sns.barplot(user_rating.index, user_rating.values, palette='bright');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T15:53:03.207174Z",
     "start_time": "2019-12-23T15:53:02.966339Z"
    }
   },
   "outputs": [],
   "source": [
    "sc = df.select_dtypes(include ='object')\n",
    "sc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T15:48:48.580387Z",
     "start_time": "2019-12-23T15:48:48.443628Z"
    }
   },
   "outputs": [],
   "source": [
    "# make copy of dataframe:\n",
    "# df_copy= df.copy()\n",
    "\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:35:56.357194Z",
     "start_time": "2019-12-23T16:35:56.143293Z"
    }
   },
   "outputs": [],
   "source": [
    "# cc = df.select_dtypes(include ='object')\n",
    "# cc.columns\n",
    "# 'GeographicAreaName',\n",
    "# df.drop(['GeographicAreaName'],axis=1, inplace=True)\n",
    "\n",
    "cc = ['GeographicAreaName','PartyAffiliation','Medicinal','Decriminalized']\n",
    "\n",
    "for x in cc:\n",
    "    df = pd.concat([df,pd.get_dummies(df[x], prefix=x)],axis=1)\n",
    "    df.drop([x],axis=1, inplace=True)\n",
    "\n",
    "# fix column headers for new columns:\n",
    "\n",
    "df.columns.columns= df.columns.str.replace(\"'\",'',regex=True)\n",
    "df.columns= df.columns.str.replace(', ','_',regex=True)\n",
    "df.columns= df.columns.str.replace(' ','_',regex=True)\n",
    "df.columns= df.columns.str.replace('.','',regex=True)\n",
    "    \n",
    "# create features and target dataframes:\n",
    "\n",
    "df_features = df.drop(['LegalStatus','State_Code'], axis=1)\n",
    "df_target = pd.DataFrame(df['LegalStatus'])\n",
    "\n",
    "df_features = df_features.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T17:20:20.448837Z",
     "start_time": "2019-12-23T17:20:20.423410Z"
    }
   },
   "outputs": [],
   "source": [
    "df_features = df_features.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T17:20:35.045560Z",
     "start_time": "2019-12-23T17:20:34.896373Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_features.head()\n",
    "# df_target.head()\n",
    "\n",
    "for x in df_features.columns:\n",
    "    print(df_features[x].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:32:14.936542Z",
     "start_time": "2019-12-30T17:32:14.889753Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import itertools\n",
    "from itertools import combinations, cycle\n",
    "\n",
    "import statsmodels as sm\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, LabelEncoder, MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge, LassoCV, LassoLarsCV, LassoLarsIC, lasso_path, enet_path\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, classification_report, multilabel_confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.feature_selection import VarianceThreshold, f_regression, mutual_info_regression, SelectKBest, RFE, RFECV\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from scipy import stats\n",
    "import scipy.stats as st\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T02:23:20.567979Z",
     "start_time": "2019-12-28T02:23:20.508779Z"
    }
   },
   "outputs": [],
   "source": [
    "def prediction_function(model,train_x,test_x, train_y,test_y, estimate=None):\n",
    "    \n",
    "    cols = [i for i in df.columns if i not in df['Legalized']]\n",
    "    \n",
    "    model.fit(train_x,train_y)\n",
    "    predictions = model.predict(test_x)\n",
    "    probabilities = model.predict_proba(test_x)\n",
    "    \n",
    "    predict_train = model.predict(train_x)\n",
    "    prob_train = model.predict_proba(train_x)\n",
    "    \n",
    "    \n",
    "    if estimate == 'dec_tree':\n",
    "        coefficients = pd.DataFrame(model.feature_importances_)\n",
    "    elif estimate == 'rfe':\n",
    "        coefficients = pd.DataFrame(model.estimator_.coef_.ravel())\n",
    "    else:\n",
    "        coefficients = pd.DataFrame(model.coef_.ravel())\n",
    "    \n",
    "    column_df = pd.DataFrame(cols)\n",
    "    coef_sumry = (pd.merge(coefficients,column_df,left_index= True,right_index= True, how = \"left\"))\n",
    "    coef_sumry.columns = [\"coefficients\",\"features\"]\n",
    "    coef_sumry = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n",
    "    \n",
    "    print (model)\n",
    "    print (\"\\n Score Report : \\n\",classification_report(test_y,predictions))\n",
    "    print (\"Accuracy Score : \",accuracy_score(test_y,predictions))\n",
    "    print ('Training Root Mean Square Error',np.sqrt(metrics.mean_squared_error(train_y,predict_train)))\n",
    "    print ('Testing Root Mean Square Error',np.sqrt(metrics.mean_squared_error(test_y,predictions)))\n",
    "    \n",
    "    \n",
    "    c_matrix = confusion_matrix(test_y,predictions)\n",
    "    cnf_matrix = pd.DataFrame(c_matrix)\n",
    "    \n",
    "    model_roc_auc = roc_auc_score(test_y,predictions) \n",
    "    print (\"AUC : \",model_roc_auc,\"\\n\")\n",
    "    test_fpr,test_tpr,test_thresholds = roc_curve(test_y, probabilities[:,1])\n",
    "    train_fpr,train_tpr,train_thresholds = roc_curve(train_y, prob_train[:,1])\n",
    "    \n",
    "    trace1 = go.Heatmap(z = cnf_matrix ,\n",
    "                        x = [0,1],\n",
    "                        y = [0,1],\n",
    "                        showscale  = False,colorscale = \"Viridis\",\n",
    "                        name = \"matrix\")\n",
    "    \n",
    "    trace2 = go.Scatter(x = test_fpr,y = test_tpr,\n",
    "                        name = \"ROC Test\",\n",
    "                        line = dict(color = ('rgb(22, 96, 167)'),width = 2))\n",
    "    \n",
    "    trace3 = go.Scatter(x = [0,1],y=[0,1],\n",
    "                        line = dict(color = ('rgb(205, 12, 24)'),width = 2,\n",
    "                        dash = 'dot'))\n",
    "    \n",
    "    trace4 = go.Scatter(x = train_fpr,y=train_tpr,\n",
    "                        name= \"ROC Train\",\n",
    "                        line = dict(color = ('rgb(255, 128, 0)'),width = 2))\n",
    "    \n",
    "    trace5 = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n",
    "                    name = \"coefficients\",\n",
    "                    marker = dict(color = coef_sumry[\"coefficients\"],\n",
    "                                  colorscale = \"Picnic\",\n",
    "                                  line = dict(width = .6,color = \"black\")))\n",
    "    \n",
    "    fig = make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n",
    "                            subplot_titles=('ROC Curve','Confusion Matrix','Feature Ranking'))\n",
    "    \n",
    "    fig.append_trace(trace1,1,2)\n",
    "    fig.append_trace(trace2,1,1)\n",
    "    fig.append_trace(trace3,1,1)\n",
    "    fig.append_trace(trace4,1,1)\n",
    "    fig.append_trace(trace5,2,1)\n",
    "    \n",
    "    fig['layout'].update(showlegend=False, title=\"Model Performance\" ,\n",
    "                         autosize = False,height = 900,width = 800,\n",
    "                         plot_bgcolor = 'rgba(240,240,240, 0.95)',\n",
    "                         paper_bgcolor = 'rgba(240,240,240, 0.95)',\n",
    "                         margin = dict(b = 195))\n",
    "    \n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T01:08:51.265302Z",
     "start_time": "2019-12-27T01:08:51.248897Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_score(model,train_x,test_x,train_y,test_y,name):\n",
    "    model.fit(train_x,train_y)\n",
    "    predictions  = model.predict(test_x)\n",
    "    accuracy     = accuracy_score(test_y,predictions)\n",
    "    recallscore  = recall_score(test_y,predictions)\n",
    "    precision    = precision_score(test_y,predictions)\n",
    "    roc_auc      = roc_auc_score(test_y,predictions)\n",
    "    f1score      = f1_score(test_y,predictions) \n",
    "    \n",
    "    df = pd.DataFrame({\"Model\"           : [name],\n",
    "                       \"Accuracy_score\"  : [accuracy],\n",
    "                       \"Recall_score\"    : [recallscore],\n",
    "                       \"Precision\"       : [precision],\n",
    "                       \"f1_score\"        : [f1score],\n",
    "                       \"Area_under_curve\": [roc_auc]})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:11:28.771577Z",
     "start_time": "2019-12-23T16:11:28.765125Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_compare(metric,color) :\n",
    "    chart = go.Bar(y = model_performances[\"Model\"] ,\n",
    "                    x = model_performances[metric],\n",
    "                    orientation = \"h\",name = metric ,\n",
    "                    marker = dict(line = dict(width =.7),\n",
    "                                  color = color))\n",
    "    return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T16:11:59.626178Z",
     "start_time": "2019-12-23T16:11:59.620940Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_acc_and_f1_score(true, preds, model_name):\n",
    "    acc = accuracy_score(true, preds)\n",
    "    f1 = f1_score(true, preds)\n",
    "    print(\"Model: {}\".format(model_name))\n",
    "    print(\"Accuracy: {}\".format(acc))\n",
    "    print(\"F1-Score: {}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T19:27:17.024897Z",
     "start_time": "2019-12-27T19:27:16.951063Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiColumnLabelEncoder:\n",
    "    \n",
    "    def __init__(self, columns = None):\n",
    "        self.columns = columns # list of column to encode\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        \n",
    "        output = X.copy()\n",
    "        \n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname, col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        \n",
    "        return output\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T23:16:24.990597Z",
     "start_time": "2019-12-28T23:16:24.960809Z"
    }
   },
   "outputs": [],
   "source": [
    "# use target encoding for categorical features:\n",
    "\n",
    "def calc_smooth_mean(df, by, on, m):\n",
    "    # Compute the global mean\n",
    "    mean = df[on].mean()\n",
    "\n",
    "    # Compute the number of values and the mean of each group\n",
    "    agg = df.groupby(by)[on].agg(['count', 'mean'])\n",
    "    counts = agg['count']\n",
    "    means = agg['mean']\n",
    "\n",
    "    # Compute the \"smoothed\" means\n",
    "    smooth = (counts * means + m * mean) / (counts + m)\n",
    "\n",
    "    # Replace each value by the according smoothed mean\n",
    "    return df[by].map(smooth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct Test of Legalized Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:23:06.064759Z",
     "start_time": "2019-12-29T22:23:05.880056Z"
    }
   },
   "outputs": [],
   "source": [
    "# instantiate encoders:\n",
    "le = LabelEncoder()\n",
    "ohc = OneHotEncoder()\n",
    "\n",
    "# make copy of dataframe:\n",
    "df = df_copy.copy()\n",
    "\n",
    "# ============================================================================== #\n",
    "\n",
    "# select columns to be removed:\n",
    "dcol = [\n",
    "'GeographicAreaName',\n",
    "'State_Code',\n",
    "'EstimateRACETotalpopulationTwoormoreracesWhiteandAmericanIndianandAlaskaNative',\n",
    "'EstimateRACETotalpopulationTwoormoreracesBlackorAfricanAmericanandAmericanIndianandAlaskaNative',\n",
    "'EstimateRacealoneorincombinationwithoneormoreotherracesTotalpopulationAmericanIndianandAlaskaNative',\n",
    "'VoteDifferenceC_T',\n",
    "'VoteDifferenceT_C',\n",
    "'2012TotalVotes',\n",
    "'ClintonBWObama',\n",
    "'TrumpBWRomney',\n",
    "'ClintonPctBWObama',\n",
    "'TrumpPctBWRomney',\n",
    "'2010LandArea',\n",
    "'Density',\n",
    "'CombinedFIPSCode',\n",
    "'CountyFIPSCode',\n",
    "'CBSACode',\n",
    "'CSACode',\n",
    "'MetropolitanDivisionCode']\n",
    "\n",
    "\n",
    "for x in dcol:\n",
    "    df.drop([x], axis=1, inplace=True)\n",
    "\n",
    "# ============================================================================== #\n",
    "\n",
    "# remove columns where constant value equals zero:\n",
    "df = df.loc[:, (df != df.iloc[0]).any()] \n",
    "\n",
    "# ============================================================================== #\n",
    "\n",
    "# create column for testing:\n",
    "df['Legalized']=df['LegalStatus']\n",
    "\n",
    "# update test column:\n",
    "df.iloc[:,-1].replace('Fully Legal','Yes',inplace=True)\n",
    "df.iloc[:,-1].replace('Fully Illegal','No',inplace=True)\n",
    "df.iloc[:,-1].replace('Mixed','No',inplace=True)\n",
    "\n",
    "# drop columns:\n",
    "df.drop(['LegalStatus'], axis=1,inplace=True)\n",
    "df.drop(['Decriminalized'], axis=1, inplace=True)\n",
    "\n",
    "# label encoding:\n",
    "df['PartyAffiliation']= le.fit_transform(df['PartyAffiliation'])\n",
    "df['Legalized']= le.fit_transform(df['Legalized'])\n",
    "\n",
    "# combine adherents:\n",
    "df1['Mathematics_score']=df1['Mathematics1_score'] + df1['Mathematics2_score']\n",
    "print(df1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LegalStatus = ',df_copy['LegalStatus'].unique())\n",
    "print('Decriminalized = ',df_copy['Decriminalized'].unique())\n",
    "print('Medicinal = ',df_copy['Medicinal'].unique())\n",
    "print('PartyAffiliation = ',df_copy['PartyAffiliation'].unique())\n",
    "print('Legalized = ',df['Legalized'].unique())\n",
    "\n",
    "# LegalStatus =  ['Fully Illegal' 'Fully Legal' 'Mixed'];  Fully Illegal = 0, Mixed = 1, Fully Legal = 2\n",
    "# Decriminalized =  ['No' 'Yes' 'Reduced']; No = 0, Reduced = 1, Yes = 2\n",
    "# Medicinal =  ['No' 'Yes' 'CBD Oil']; No = 0, CBD Oil = 1, Yes = 2\n",
    "# PartyAffiliation =  ['Republican' 'Democrat']; Label Encoder\n",
    "# Legalized =  ['No' 'Yes']; Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:14:34.387753Z",
     "start_time": "2019-12-29T22:14:34.358280Z"
    }
   },
   "outputs": [],
   "source": [
    "# label encoding:\n",
    "\n",
    "# df['PartyAffiliation']= le.fit_transform(df['PartyAffiliation'])\n",
    "# df['Legalized']= le.fit_transform(df['Legalized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T23:21:15.411139Z",
     "start_time": "2019-12-28T23:21:15.353091Z"
    }
   },
   "outputs": [],
   "source": [
    "#target encoding:\n",
    "\n",
    "# df['GeographicAreaName'] = calc_smooth_mean(df, by='GeographicAreaName', on='Legalized', m=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T21:49:09.889690Z",
     "start_time": "2019-12-29T21:49:09.757634Z"
    }
   },
   "outputs": [],
   "source": [
    "# ordinal encoding:\n",
    "\n",
    "# ordinalencoder = OrdinalEncoder()\n",
    "# ordinalencoder.fit_transform(df[['LegalStatus']])\n",
    "\n",
    "# # Using pandas factorize method for ordinal data\n",
    "# categories1 = pd.Categorical(df['LegalStatus'], categories=['Fully Illegal', 'Mixed', 'Fully Legal'], ordered=True) # Order of labels set for data\n",
    "\n",
    "\n",
    "# # Factorizing the column data\n",
    "# labels1, unique = pd.factorize(categories1, sort=True)\n",
    "# df['LegalStatus'] = labels1  # Encoded Legal Status\n",
    "\n",
    "\n",
    "# ordinalencoder.fit_transform(df[['Decriminalized']])\n",
    "\n",
    "# # Using pandas factorize method for ordinal data\n",
    "# categories2 = pd.Categorical(df['Decriminalized'], categories=['No', 'Reduced', 'Yes'], ordered=True) # Order of labels set for data\n",
    "\n",
    "# # Factorizing the column data\n",
    "# labels2, unique = pd.factorize(categories2, sort=True)\n",
    "# df['Decriminalized'] = labels2  # Encoded Legal Status\n",
    "\n",
    "\n",
    "# ordinalencoder.fit_transform(df[['Medicinal']])\n",
    "\n",
    "# # Using pandas factorize method for ordinal data\n",
    "# categories3 = pd.Categorical(df['Medicinal'], categories=['No', 'CBD Oil', 'Yes'], ordered=True) # Order of labels set for data\n",
    "\n",
    "# # Factorizing the column data\n",
    "# labels3, unique = pd.factorize(categories3, sort=True)\n",
    "# df['Medicinal'] = labels3  # Encoded Legal Status\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T21:49:26.865490Z",
     "start_time": "2019-12-29T21:49:26.624707Z"
    }
   },
   "outputs": [],
   "source": [
    "# binary encoding for all 50 states:\n",
    "\n",
    "# import category_encoders as ce\n",
    "\n",
    "# encoder = ce.BinaryEncoder(cols=['State_Code'])\n",
    "# df = encoder.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:24:05.191084Z",
     "start_time": "2019-12-29T22:24:05.021570Z"
    }
   },
   "outputs": [],
   "source": [
    "#target encoding:\n",
    "chk = df.select_dtypes(include ='object')\n",
    "c = chk.columns\n",
    "\n",
    "for x in chk.columns:\n",
    "    df[x] = calc_smooth_mean(df, by=x, on='Legalized', m=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:24:19.983867Z",
     "start_time": "2019-12-29T22:24:19.943946Z"
    }
   },
   "outputs": [],
   "source": [
    "# check categorical columns:\n",
    "chk = df.select_dtypes(include ='object')\n",
    "chk.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:26:04.556415Z",
     "start_time": "2019-12-29T22:26:04.329123Z"
    }
   },
   "outputs": [],
   "source": [
    "# check for columns with zeros comprising at least 50%:\n",
    "cols = list(df.columns[df[df == 0].count(axis=0)/len(df.index)>0.5])\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:26:19.457940Z",
     "start_time": "2019-12-29T22:26:19.254968Z"
    }
   },
   "outputs": [],
   "source": [
    "# find columns where zero count > 50%:\n",
    "cols = list(df.columns[df[df == 0].count(axis=0)/len(df.index)>0.5])\n",
    "\n",
    "# remove items that should not be dropped from dataframe:\n",
    "# for x in ['State_Code_0','State_Code_1', 'State_Code_2', 'State_Code_3', 'State_Code_4','State_Code_5', 'State_Code_6',\n",
    "# 'Legalized']:\n",
    "#     cols.remove(x)\n",
    "\n",
    "for x in ['Legalized']:\n",
    "    cols.remove(x)\n",
    "    \n",
    "# drop columns from dataframe:\n",
    "for x in cols:\n",
    "    df.drop([x], axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:42:19.926044Z",
     "start_time": "2019-12-29T22:42:19.811156Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:42:01.208565Z",
     "start_time": "2019-12-29T22:42:01.081050Z"
    }
   },
   "outputs": [],
   "source": [
    "# create features and target dataframes:\n",
    "\n",
    "df_features = df.drop(['Legalized'], axis=1)\n",
    "df_target = df['Legalized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:48:55.976565Z",
     "start_time": "2019-12-29T22:43:05.657975Z"
    }
   },
   "outputs": [],
   "source": [
    "profile_new = df.profile_report()\n",
    "rejected_variables_new = profile_new.get_rejected_variables(threshold=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:50:07.298855Z",
     "start_time": "2019-12-29T22:50:07.286565Z"
    }
   },
   "outputs": [],
   "source": [
    "rejected_variables_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:50:29.299093Z",
     "start_time": "2019-12-29T22:50:28.693817Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profile_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:52:14.029747Z",
     "start_time": "2019-12-29T22:52:13.525789Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_features\n",
    "y = df_target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n",
    "\n",
    "logreg = LogisticRegression() \n",
    "baseline_log = logreg.fit(X_train, y_train)\n",
    "print(baseline_log) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:52:33.022966Z",
     "start_time": "2019-12-29T22:52:29.853745Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction_function(baseline_log, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:53:41.401736Z",
     "start_time": "2019-12-29T22:53:41.338294Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_trans = scaler.transform(X_train)\n",
    "X_train_transformed = pd.DataFrame(X_trans, columns=X_train.columns, index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:53:50.244627Z",
     "start_time": "2019-12-29T22:53:50.191116Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(X_test)\n",
    "X_testy = scaler.transform(X_test)\n",
    "X_test_transformed = pd.DataFrame(X_testy, columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:54:02.084462Z",
     "start_time": "2019-12-29T22:54:01.899371Z"
    }
   },
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_smote_train, y_smote_train = smote.fit_sample(X_train_transformed, y_train) \n",
    "X_smote_test, y_smote_test = smote.fit_sample(X_test_transformed, y_test) \n",
    "smote_log = LogisticRegression(fit_intercept = False, C = 1e12,solver ='lbfgs', random_state=123)\n",
    "smote_logit = smote_log.fit(X_smote_train, y_smote_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:54:30.351685Z",
     "start_time": "2019-12-29T22:54:29.039012Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction_function(smote_logit, X_smote_train, X_smote_test, y_smote_train, y_smote_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats = model.predict(X)\n",
    "\n",
    "df['y_hats'] = y_hats.reset_index()['name of the target column']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:55:26.203617Z",
     "start_time": "2019-12-29T22:55:25.029301Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_lasso = LogisticRegression(penalty='l1', random_state=123)\n",
    "logit_lasso = log_lasso.fit(X_train_transformed,y_train)\n",
    "prediction_function(logit_lasso,X_train_transformed,X_test_transformed,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Model (Balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:55:49.811719Z",
     "start_time": "2019-12-29T22:55:49.101789Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge_logreg = LogisticRegression(class_weight='balanced', random_state=123)\n",
    "ridge_logit = ridge_logreg.fit(X_train_transformed,y_train)\n",
    "\n",
    "prediction_function(ridge_logit,X_train_transformed,X_test_transformed,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:56:17.759579Z",
     "start_time": "2019-12-29T22:56:16.057286Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "rfe = RFE(logit, 10)\n",
    "X_rfe_train = rfe.fit_transform(X_train_transformed,y_train)\n",
    "X_rfe_test = rfe.transform(X_test_transformed)\n",
    "rfe = rfe.fit(X_rfe_train,y_train.values.ravel())\n",
    "prediction_function(rfe,X_rfe_train,X_rfe_test,y_train,y_test, 'rfe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:57:19.178107Z",
     "start_time": "2019-12-29T22:57:19.074015Z"
    }
   },
   "outputs": [],
   "source": [
    "pca_X2 = df_features\n",
    "pca_y2 = df_target\n",
    "\n",
    "pca_X_train2, pca_X_test2, pca_y_train2, pca_y_test2 = train_test_split(pca_X2, pca_y2, test_size=0.20, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:57:34.588962Z",
     "start_time": "2019-12-29T22:57:34.386524Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca_train = pca.fit_transform(pca_X_train_transformed2)\n",
    "pca_test = pca.transform(pca_X_test_transformed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T22:57:47.995994Z",
     "start_time": "2019-12-29T22:57:47.132224Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:00:44.514027Z",
     "start_time": "2019-12-29T23:00:44.431976Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=15)\n",
    "pca_X_train_transformed2 = pca.fit_transform(pca_X_train_transformed2)\n",
    "pca_X_test_transformed2 = pca.transform(pca_X_test_transformed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:01:11.363285Z",
     "start_time": "2019-12-29T23:01:10.616667Z"
    }
   },
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame({'var': pca.explained_variance_ratio_, 'Principal Component': ['PC1', 'PC2', 'PC3', 'PC4','PC5','PC6','PC7','PC8','PC9','PC10',\n",
    "                                                                   'PC11', 'PC12', 'PC13', 'PC14','PC15']})\n",
    "#                                                                     ,'PC16','PC17','PC18','PC19','PC20',\n",
    "#                                                                    'PC21', 'PC22', 'PC23', 'PC24','PC25','PC26','PC27','PC28','PC29','PC30',\n",
    "#                                                                    'PC31', 'PC32', 'PC33', 'PC34','PC35','PC36','PC37','PC38','PC39','PC40']})\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.barplot(x='Principal Component', y='var', data=pca_df, color='c');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T16:02:28.939536Z",
     "start_time": "2019-12-30T16:02:28.916953Z"
    }
   },
   "outputs": [],
   "source": [
    "print (pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:01:28.855200Z",
     "start_time": "2019-12-29T23:01:28.786129Z"
    }
   },
   "outputs": [],
   "source": [
    "X2 = df_features\n",
    "y2 = df_target\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:01:40.626636Z",
     "start_time": "2019-12-29T23:01:40.585659Z"
    }
   },
   "outputs": [],
   "source": [
    "mm_scaler = MinMaxScaler().fit(X_train2)\n",
    "X_trans2 = mm_scaler.transform(X_train2)\n",
    "X_train_transformed2 = pd.DataFrame(X_trans2, columns=X_train2.columns, index=X_train2.index)\n",
    "\n",
    "mm_scaler = MinMaxScaler().fit(X_test2)\n",
    "X_testy2 = mm_scaler.transform(X_test2)\n",
    "X_test_transformed2 = pd.DataFrame(X_testy2, columns=X_test2.columns, index=X_test2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:02:10.485059Z",
     "start_time": "2019-12-29T23:02:10.399705Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_tree = DecisionTreeClassifier(criterion='gini', max_depth=7, random_state=123, class_weight='balanced')\n",
    "dec_tree = clf_tree.fit(X_train_transformed2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:02:29.580531Z",
     "start_time": "2019-12-29T23:02:27.037069Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = clf_tree.predict(X_test_transformed2)\n",
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_depth in max_depths:\n",
    "   dt = DecisionTreeClassifier(criterion='entropy', max_depth=max_depth)\n",
    "   dt.fit(X_train_transformed2, y_train2)\n",
    "   train_pred = dt.predict(X_train_transformed2)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train2, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   # Add auc score to previous train results\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = dt.predict(X_test_transformed2)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test2, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   # Add auc score to previous test results\n",
    "   test_results.append(roc_auc)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(max_depths, train_results, 'b', label='Train AUC')\n",
    "plt.plot(max_depths, test_results, 'r', label='Test AUC')\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:02:45.326189Z",
     "start_time": "2019-12-29T23:02:44.089860Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction_function(dec_tree,X_train_transformed2,X_test_transformed2,y_train2,y_test2,estimate='dec_tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:03:13.144496Z",
     "start_time": "2019-12-29T23:03:12.961396Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_forest = RandomForestClassifier()\n",
    "mean_baseline_forest = np.mean(cross_val_score(baseline_forest, X_train_transformed2, y_train2, cv=3))\n",
    "\n",
    "print(f\"Mean Cross Val Score for Random Forest: {mean_baseline_forest :.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:03:26.701337Z",
     "start_time": "2019-12-29T23:03:26.692048Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    'n_estimators': [10, 30, 100],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 2, 6, 10],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [3, 6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:04:09.287406Z",
     "start_time": "2019-12-29T23:03:39.492020Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_grid_search = GridSearchCV(baseline_forest, rf_param_grid, cv=3)\n",
    "rf_grid_search.fit(X_train_transformed2, y_train2)\n",
    "\n",
    "print(f\"Training Accuracy: {rf_grid_search.best_score_ :.2%}\")\n",
    "print(\"\")\n",
    "print(f\"Optimal Parameters: {rf_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:05:14.028772Z",
     "start_time": "2019-12-29T23:05:13.964864Z"
    }
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(criterion='entropy', max_depth=6, min_samples_leaf=3, min_samples_split=5, n_estimators=10)\n",
    "forest.fit(X_train_transformed2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:05:28.610142Z",
     "start_time": "2019-12-29T23:05:28.595003Z"
    }
   },
   "outputs": [],
   "source": [
    "forest.score(X_train_transformed2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:05:40.002317Z",
     "start_time": "2019-12-29T23:05:39.983745Z"
    }
   },
   "outputs": [],
   "source": [
    "forest.score(X_test_transformed2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:05:40.237623Z",
     "start_time": "2019-12-30T18:05:39.361874Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# random forest feature importance:\n",
    "n=10\n",
    "col_sorted_by_importance=forest.feature_importances_.argsort()[::-1][:n]\n",
    "feat_imp=pd.DataFrame({\n",
    "    'Features':X_train_transformed2.columns[col_sorted_by_importance],\n",
    "    'Importance':forest.feature_importances_[col_sorted_by_importance]\n",
    "})\n",
    "\n",
    "import plotly.express as px\n",
    "px.bar(feat_imp, x='Features', y='Importance',title=\"Random Forest Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:05:57.060494Z",
     "start_time": "2019-12-29T23:05:56.017249Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_clf_baseline = xgb.XGBClassifier()\n",
    "xgb_clf_baseline.fit(X_train_transformed2, y_train2)\n",
    "training_preds = xgb_clf_baseline.predict(X_train_transformed2)\n",
    "val_preds = xgb_clf_baseline.predict(X_test_transformed2)\n",
    "training_accuracy = accuracy_score(y_train2, training_preds)\n",
    "val_accuracy = accuracy_score(y_test2, val_preds)\n",
    "\n",
    "print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:06:10.595989Z",
     "start_time": "2019-12-29T23:06:10.586256Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\": [1.0, 0.5, 0.1, 0.01],\n",
    "    'max_depth': [1, 2, 4, 6, 10],\n",
    "    'min_child_weight': [10],\n",
    "    'subsample': [0.7, 0.8],\n",
    "    'n_estimators': [3, 5, 30, 100, 250],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:08:04.403569Z",
     "start_time": "2019-12-29T23:06:25.883774Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(xgb_clf_baseline, param_grid, scoring='accuracy', cv=3, n_jobs=4)\n",
    "grid_clf.fit(X_train_transformed2, y_train2)\n",
    "\n",
    "best_parameters = grid_clf.best_params_\n",
    "\n",
    "print(\"Grid Search found the following optimal parameters: \")\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:08:30.386514Z",
     "start_time": "2019-12-29T23:08:30.309722Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(learning_rate=1.0, max_depth=2, min_child_weight=10, n_estimators=5, subsample=0.7)\n",
    "xgb_clf.fit(X_train_transformed2, y_train2)\n",
    "training_preds = xgb_clf.predict(X_train_transformed2)\n",
    "val_preds = xgb_clf.predict(X_test_transformed2)\n",
    "training_accuracy = accuracy_score(y_train2, training_preds)\n",
    "val_accuracy = accuracy_score(y_test2, val_preds)\n",
    "\n",
    "print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:40:16.410201Z",
     "start_time": "2019-12-30T18:40:15.671138Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# top 10 xgbost features:\n",
    "xgb.plot_importance(xgb_clf_baseline,max_num_features=10)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:36:30.499390Z",
     "start_time": "2019-12-30T18:36:29.809657Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xgboost feature importance:\n",
    "n=10\n",
    "col_sorted_by_importance=xgb_clf_baseline.feature_importances_.argsort()[::-1][:n]\n",
    "feat_imp=pd.DataFrame({\n",
    "    'Features':X_train_transformed2.columns[col_sorted_by_importance],\n",
    "    'Importance':xgb_clf_baseline.feature_importances_[col_sorted_by_importance]\n",
    "})\n",
    "\n",
    "import plotly.express as px\n",
    "px.bar(feat_imp, x='Features', y='Importance',title=\"XGBoost Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:08:45.797708Z",
     "start_time": "2019-12-29T23:08:45.205082Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate an AdaBoostClassifier\n",
    "adaboost_clf = AdaBoostClassifier(random_state=123)\n",
    "adaboost_clf.fit(X_train_transformed2, y_train2)\n",
    "adaboost_train_preds = adaboost_clf.predict(X_train_transformed2)\n",
    "adaboost_test_preds = adaboost_clf.predict(X_test_transformed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:08:57.058746Z",
     "start_time": "2019-12-29T23:08:57.042491Z"
    }
   },
   "outputs": [],
   "source": [
    "adaboost_confusion_matrix = confusion_matrix(y_test2, adaboost_test_preds)\n",
    "adaboost_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:10:04.249750Z",
     "start_time": "2019-12-29T23:10:04.215099Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"AdaBoost Training Metrics\")\n",
    "display_acc_and_f1_score(y_train2, adaboost_train_preds, model_name='AdaBoost')\n",
    "print(\"\")\n",
    "print(\"AdaBoost Testing Metrics\")\n",
    "display_acc_and_f1_score(y_test2, adaboost_test_preds, model_name='AdaBoost')\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:11:17.616312Z",
     "start_time": "2019-12-29T23:11:17.570560Z"
    }
   },
   "outputs": [],
   "source": [
    "adaboost_classification_report = classification_report(y_test2, adaboost_test_preds)\n",
    "print(adaboost_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:11:47.344535Z",
     "start_time": "2019-12-29T23:11:44.611104Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Mean Adaboost Cross-Val Score (k=5):')\n",
    "print(cross_val_score(adaboost_clf, X2, y2, cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:12:14.119110Z",
     "start_time": "2019-12-29T23:12:14.110397Z"
    }
   },
   "outputs": [],
   "source": [
    "adaboost_param_grid = {\n",
    "    'n_estimators': [50, 100, 250],\n",
    "    'learning_rate': [1.0, 0.5, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:13:15.960126Z",
     "start_time": "2019-12-29T23:12:50.314050Z"
    }
   },
   "outputs": [],
   "source": [
    "adaboost_grid_search = GridSearchCV(adaboost_clf, adaboost_param_grid, cv=3)\n",
    "adaboost_grid_search.fit(X_train_transformed2, y_train2)\n",
    "\n",
    "print(f\"Training Accuracy: {adaboost_grid_search.best_score_ :.2%}\")\n",
    "print(\"\")\n",
    "print(f\"Optimal Parameters: {adaboost_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:13:51.810797Z",
     "start_time": "2019-12-29T23:13:51.727566Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adb_score = adaboost_grid_search.score(X_test_transformed2, y_test2)\n",
    "print('Adaboost grid search: ', adb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:27:04.134097Z",
     "start_time": "2019-12-30T18:27:03.196916Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adaboost feature importance:\n",
    "n=10\n",
    "col_sorted_by_importance=adaboost_clf.feature_importances_.argsort()[::-1][:n]\n",
    "feat_imp=pd.DataFrame({\n",
    "    'Features':X_train_transformed2.columns[col_sorted_by_importance],\n",
    "    'Importance':adaboost_clf.feature_importances_[col_sorted_by_importance]\n",
    "})\n",
    "\n",
    "import plotly.express as px\n",
    "px.bar(feat_imp, x='Features', y='Importance',title=\"AdaBoost Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:14:13.408538Z",
     "start_time": "2019-12-29T23:14:12.345755Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate a GradientBoostingClassifier\n",
    "gbt_clf = GradientBoostingClassifier(random_state=123)\n",
    "gbt_clf.fit(X_train_transformed2, y_train2)\n",
    "gbt_clf_train_preds = gbt_clf.predict(X_train_transformed2)\n",
    "gbt_clf_test_preds = gbt_clf.predict(X_test_transformed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:14:24.853953Z",
     "start_time": "2019-12-29T23:14:24.816971Z"
    }
   },
   "outputs": [],
   "source": [
    "gbt_confusion_matrix = confusion_matrix(y_test2, gbt_clf_test_preds)\n",
    "gbt_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:14:42.248635Z",
     "start_time": "2019-12-29T23:14:42.222042Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"GBT Training Metrics\")\n",
    "display_acc_and_f1_score(y_train2, gbt_clf_train_preds, model_name='Gradient Boosted Trees')\n",
    "print(\"\")\n",
    "print(\"GBT Testing Metrics\")\n",
    "display_acc_and_f1_score(y_test2, gbt_clf_test_preds, model_name='Gradient Boosted Trees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:15:04.794656Z",
     "start_time": "2019-12-29T23:15:04.779160Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbt_classification_report = classification_report(y_test2, gbt_clf_test_preds)\n",
    "print(gbt_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:15:28.835001Z",
     "start_time": "2019-12-29T23:15:23.814310Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Mean GBT Cross-Val Score (k=5):')\n",
    "print(cross_val_score(gbt_clf, X2, y2, cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:53:33.664536Z",
     "start_time": "2019-12-30T18:53:32.399478Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gradient boost feature importance:\n",
    "\n",
    "n=10\n",
    "col_sorted_by_importance=gbt_clf.feature_importances_.argsort()[::-1][:n]\n",
    "feat_imp=pd.DataFrame({\n",
    "    'Features':X_train_transformed2.columns[col_sorted_by_importance],\n",
    "    'Importance':gbt_clf.feature_importances_[col_sorted_by_importance]\n",
    "})\n",
    "\n",
    "import plotly.express as px\n",
    "px.bar(feat_imp, x='Features', y='Importance',title=\"Gradient Boost Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:16:16.096939Z",
     "start_time": "2019-12-29T23:16:15.857283Z"
    }
   },
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train_transformed2, y_train2)\n",
    "knn_clf_train_preds = knn_clf.predict(X_train_transformed2)\n",
    "knn_clf_test_preds = knn_clf.predict(X_test_transformed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:16:28.255283Z",
     "start_time": "2019-12-29T23:16:28.239315Z"
    }
   },
   "outputs": [],
   "source": [
    "knn_confusion_matrix = confusion_matrix(y_test2, knn_clf_test_preds)\n",
    "knn_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:17:03.227663Z",
     "start_time": "2019-12-29T23:17:03.207327Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"KNN Training Metrics\")\n",
    "display_acc_and_f1_score(y_train2, knn_clf_train_preds, model_name='K-Nearest Neighbors')\n",
    "print(\"\")\n",
    "print(\"KNN Testing Metrics\")\n",
    "display_acc_and_f1_score(y_test2, knn_clf_test_preds, model_name='K-Nearest Neighbors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:17:29.212008Z",
     "start_time": "2019-12-29T23:17:29.195685Z"
    }
   },
   "outputs": [],
   "source": [
    "knn_classification_report = classification_report(y_test2, knn_clf_test_preds)\n",
    "print(knn_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:17:44.420843Z",
     "start_time": "2019-12-29T23:17:44.268052Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Mean KNN Cross-Val Score (k=5):')\n",
    "print(cross_val_score(knn_clf, X2, y2, cv=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.13\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble / Meta-Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:18:39.906961Z",
     "start_time": "2019-12-29T23:18:38.444228Z"
    }
   },
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(estimators=[('KNN', knn_clf), ('GBT', gbt_clf), ('XGB', xgb_clf), ('RF', forest)], voting='soft')\n",
    "eclf.fit(X_train_transformed2, y_train2)\n",
    "eclf_train_preds = eclf.predict(X_train_transformed2)\n",
    "eclf_test_preds = eclf.predict(X_test_transformed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:18:52.513300Z",
     "start_time": "2019-12-29T23:18:52.488748Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"ECLF Training Metrics\")\n",
    "display_acc_and_f1_score(y_train2, eclf_train_preds, model_name='ECLF')\n",
    "print(\"\")\n",
    "print(\"ECLF Testing Metrics\")\n",
    "display_acc_and_f1_score(y_test2, eclf_test_preds, model_name='ECLF')\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:19:15.090383Z",
     "start_time": "2019-12-29T23:19:15.072991Z"
    }
   },
   "outputs": [],
   "source": [
    "eclf_classification_report = classification_report(y_test2, eclf_test_preds)\n",
    "print(eclf_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison - Intermediate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:19:35.811052Z",
     "start_time": "2019-12-29T23:19:33.086488Z"
    }
   },
   "outputs": [],
   "source": [
    "model1 = model_score(baseline_log, X_train, X_test, y_train, y_test,\"Baseline\")\n",
    "model2 = model_score(smote_logit, X_smote_train, X_smote_test, y_smote_train, y_smote_test,\"SMOTE\")\n",
    "model3 = model_score(rfe,X_rfe_train,X_rfe_test,y_train,y_test,\"RFE\")\n",
    "model4 = model_score(logit_lasso,X_train_transformed,X_test_transformed,y_train,y_test,\"Lasso\")\n",
    "model5 = model_score(ridge_logit,X_train_transformed,X_test_transformed,y_train,y_test, \"Ridge\")\n",
    "\n",
    "model_performances = pd.concat([model1,model2,model3,model4,model5],axis = 0).reset_index()\n",
    "model_performances = model_performances.drop(columns = \"index\",axis =1)\n",
    "\n",
    "dataframe  = ff.create_table(np.round(model_performances,4))\n",
    "\n",
    "py.iplot(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:20:07.094709Z",
     "start_time": "2019-12-29T23:20:05.466786Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_performances\n",
    "\n",
    "layout = go.Layout(dict(title = \"Model Comparison\",\n",
    "                        plot_bgcolor  = \"rgb(243,243,243)\",\n",
    "                        paper_bgcolor = \"rgb(243,243,243)\",\n",
    "                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n",
    "                                     title = \"Metric\",\n",
    "                                     zerolinewidth=1,\n",
    "                                     ticklen=5,gridwidth=2),\n",
    "                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n",
    "                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n",
    "                        margin = dict(l = 250),\n",
    "                        height = 780))\n",
    "\n",
    "trace1  = model_compare(\"Accuracy_score\",\"#1bde65\")\n",
    "trace2  = model_compare('Recall_score',\"#d93311\")\n",
    "trace3  = model_compare('Precision',\"#3ae8d7\")\n",
    "trace4  = model_compare('f1_score',\"#0f3175\")\n",
    "\n",
    "data = [trace1,trace2,trace3,trace4]\n",
    "fig = go.Figure(data=data,layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison - Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:21:09.217190Z",
     "start_time": "2019-12-29T23:21:09.175304Z"
    }
   },
   "outputs": [],
   "source": [
    "def ML_model_score(model,train_x,test_x,train_y,test_y,name):\n",
    "    model.fit(train_x,train_y)\n",
    "    predictions  = model.predict(test_x)\n",
    "    accuracy     = accuracy_score(test_y,predictions)\n",
    "    recallscore  = recall_score(test_y,predictions)\n",
    "    precision    = precision_score(test_y,predictions)\n",
    "    roc_auc      = roc_auc_score(test_y,predictions)\n",
    "    f1score      = f1_score(test_y,predictions) \n",
    "    cross_val    = cross_val_score(model,X2, y2, cv=5).mean()\n",
    "    df_ML = pd.DataFrame({\"Model\"           : [name],\n",
    "                       \"Cross_Val\"       : [cross_val],\n",
    "                       \"Accuracy_score\"  : [accuracy],\n",
    "                       \"Recall_score\"    : [recallscore],\n",
    "                       \"Precision\"       : [precision],\n",
    "                       \"f1_score\"        : [f1score],\n",
    "                       \"Area_under_curve\": [roc_auc]})\n",
    "    return df_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:21:54.546690Z",
     "start_time": "2019-12-29T23:21:44.786935Z"
    }
   },
   "outputs": [],
   "source": [
    "ML_model1 = ML_model_score(dec_tree, X_train_transformed2, X_test_transformed2, y_train2, y_test2,\"Decision Tree\")\n",
    "ML_model2 = ML_model_score(forest, X_train_transformed2, X_test_transformed2, y_train2, y_test2,\"Random Forest\")\n",
    "ML_model3 = ML_model_score(xgb_clf,X_train_transformed2, X_test_transformed2, y_train2, y_test2,\"XGBoost\")\n",
    "ML_model4 = ML_model_score(adaboost_clf,X_train_transformed2, X_test_transformed2, y_train2, y_test2,\"AdaBoost\")\n",
    "ML_model5 = ML_model_score(gbt_clf,X_train_transformed2, X_test_transformed2, y_train2, y_test2, \"GBT\")\n",
    "ML_model6 = ML_model_score(knn_clf,X_train_transformed2, X_test_transformed2, y_train2, y_test2, \"KNN\")\n",
    "\n",
    "ML_model_performances = pd.concat([ML_model1,ML_model2,ML_model3,ML_model4,ML_model5,ML_model6],axis = 0).reset_index()\n",
    "ML_model_performances = ML_model_performances.drop(columns = \"index\",axis =1)\n",
    "\n",
    "ML_dataframe  = ff.create_table(np.round(ML_model_performances,4))\n",
    "\n",
    "py.iplot(ML_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:22:36.290179Z",
     "start_time": "2019-12-29T23:22:36.266809Z"
    }
   },
   "outputs": [],
   "source": [
    "def ML_model_compare(metric,color) :\n",
    "    ML_chart = go.Bar(y = ML_model_performances[\"Model\"] ,\n",
    "                    x = ML_model_performances[metric],\n",
    "                    orientation = \"h\",name = metric ,\n",
    "                    marker = dict(line = dict(width =.7),\n",
    "                                  color = color))\n",
    "    return ML_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T23:22:56.569831Z",
     "start_time": "2019-12-29T23:22:55.343865Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ML_model_performances\n",
    "\n",
    "layout = go.Layout(dict(title = \"ML Model Comparison\",\n",
    "                        plot_bgcolor  = \"rgb(243,243,243)\",\n",
    "                        paper_bgcolor = \"rgb(243,243,243)\",\n",
    "                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n",
    "                                     title = \"Metric\",\n",
    "                                     zerolinewidth=1,\n",
    "                                     ticklen=5,gridwidth=2),\n",
    "                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n",
    "                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n",
    "                        margin = dict(l = 250),\n",
    "                        height = 780))\n",
    "\n",
    "trace1  = ML_model_compare(\"Accuracy_score\",\"#1bde65\")\n",
    "trace2  = ML_model_compare('Recall_score',\"#d93311\")\n",
    "trace3  = ML_model_compare('Precision',\"#3ae8d7\")\n",
    "trace4  = ML_model_compare('f1_score',\"#0f3175\")\n",
    "trace5  = ML_model_compare('Cross_Val', \"#ddf50a\")\n",
    "data = [trace1,trace2,trace3,trace4,trace5]\n",
    "fig = go.Figure(data=data,layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T03:43:22.739803Z",
     "start_time": "2019-12-31T03:43:22.208491Z"
    }
   },
   "outputs": [],
   "source": [
    "# logistic regression predictions:\n",
    "\n",
    "df_pred = df_copy.copy()\n",
    "# create column for testing:\n",
    "df_pred['Legalized']=df_pred['LegalStatus']\n",
    "\n",
    "# update test column:\n",
    "df_pred.iloc[:,-1].replace('Fully Legal','Yes',inplace=True)\n",
    "df_pred.iloc[:,-1].replace('Fully Illegal','No',inplace=True)\n",
    "df_pred.iloc[:,-1].replace('Mixed','No',inplace=True)\n",
    "\n",
    "lrp = logreg.predict(X)\n",
    "smt = smote_log.predict(X) #\n",
    "las = log_lasso.predict(X) #\n",
    "rid = ridge_logreg.predict(X) #\n",
    "# rfelim = rfe.predict(X) #\n",
    "# pca1 = pca.predict(X)\n",
    "dt = dec_tree.predict(X) #\n",
    "rf = forest.predict(X) #\n",
    "xgb = xgb_clf.predict(X) #\n",
    "adb = adaboost_clf.predict(X) #\n",
    "gbc = gbt_clf.predict(X) #\n",
    "knn = knn_clf.predict(X) #\n",
    "ens = eclf.predict(X)\n",
    "\n",
    "df_pred['LogRegPred'] = lrp\n",
    "df_pred['SMOTEPred'] = smt\n",
    "df_pred['LassoPred'] = las\n",
    "df_pred['RidgePred'] = rid\n",
    "# df_pred['RFEPred'] = rfelim\n",
    "# df_pred['PCAPred'] = pca1\n",
    "df_pred['DecisionTreePred'] = dt\n",
    "df_pred['RandomForestPred'] = rf\n",
    "df_pred['XGBoostPred'] = xgb\n",
    "df_pred['AdaBoostPred'] = adb\n",
    "df_pred['GradientBoostPred'] = gbc\n",
    "df_pred['KNNPred'] = knn\n",
    "df_pred['EnsemblePred'] = ens\n",
    "\n",
    "\n",
    "df.columns[-2]\n",
    "legal = ['Alaska','California','Colorado','Maine','Massachusetts','Nevada',\n",
    "'Oregon','Washington','Illinois','Michigan','Vermont']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T05:21:46.477906Z",
     "start_time": "2019-12-31T05:21:46.304942Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find out states from model predictions:\n",
    "z=[]\n",
    "for x in df_pred.columns[-11:]:\n",
    "    z.append((np.unique(df_pred['State_Code'].loc[(df_pred[x] == 1) & (df_pred['Legalized'] =='No')].unique())))\n",
    "\n",
    "# flatten nested list:\n",
    "flatList = []\n",
    "for elem in z:\n",
    "    for item in elem:\n",
    "        flatList.append(item)\n",
    "# print('Flat List : ', flatList)\n",
    "\n",
    "# get model counts for each state and sort in descending order:\n",
    "counts,values = pd.Series(flatList).value_counts().values, pd.Series(flatList).value_counts().index\n",
    "df_results = pd.DataFrame(list(zip(values,counts)),columns=[\"value\",\"count\"])\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-01T22:15:19.086109Z",
     "start_time": "2020-01-01T22:15:18.743693Z"
    }
   },
   "outputs": [],
   "source": [
    "np.unique(df_pred['State_Code'].loc[(df_pred['KNNPred'] == 1) & (df_pred['Legalized'] =='No')].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-01T22:17:04.243890Z",
     "start_time": "2020-01-01T22:17:04.230375Z"
    }
   },
   "outputs": [],
   "source": [
    "np.unique(df_pred['State_Code'].loc[(df_pred['GradientBoostPred'] == 1) & (df_pred['Legalized'] =='No')].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-01T21:39:26.124379Z",
     "start_time": "2020-01-01T21:39:21.053051Z"
    }
   },
   "outputs": [],
   "source": [
    "# counts,values = df_pred.values(), df_pred.index\n",
    "# df_results = pd.DataFrame(list(zip(values,counts)),columns=[\"value\",\"count\"])\n",
    "\n",
    "fig = px.bar(df_results, x='value', y='count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T05:26:33.353485Z",
     "start_time": "2019-12-31T05:26:33.072050Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-01T16:55:05.972490Z",
     "start_time": "2020-01-01T16:55:05.938129Z"
    }
   },
   "outputs": [],
   "source": [
    "feat = [\n",
    "'Employment Industry',\n",
    "'Religion',\n",
    "'Ancestry',\n",
    "'Ancestry',\n",
    "'Commute-Walk',\n",
    "'Ancestry',\n",
    "'Ancestry',\n",
    "'Home Heating Fuel - Other',\n",
    "'Ancestry',\n",
    "'Ancestry',\n",
    "'Ancestry',\n",
    "'Home Heating Fuel - Wood',\n",
    "'Ancestry',\n",
    "'Ancestry',\n",
    "'Ancestry',\n",
    "'Ancestry',\n",
    "'Ancestry',\n",
    "'Fertility',\n",
    "'Medicinal',\n",
    "'Ancestry',\n",
    "'Home Heating Fuel - Wood',\n",
    "'Ancestry',\n",
    "'Ancestry',\n",
    "'Fertility',\n",
    "'Ancestry',\n",
    "'Religion',\n",
    "'Commute-Walk',\n",
    "'Race',\n",
    "'Sex and Age Median',\n",
    "'Race',\n",
    "'Sex and Age per 100 females - 65 and over',\n",
    "'Race',\n",
    "'Sex and Age per 100 females - 18 and over',\n",
    "'Race',\n",
    "'Race',\n",
    "'Race',\n",
    "'Party Affiliation',\n",
    "'Home Heating Fuel - Oil',\n",
    "'Race',\n",
    "'Ancestry',\n",
    "'Housing Costs',\n",
    "'Race',\n",
    "'House Tenure',\n",
    "'Ancestry',\n",
    "'Ancestry',\n",
    "'Medicinal',\n",
    "'Party Affiliation',\n",
    "'Ancestry',\n",
    "'Home Value',\n",
    "'Ancestry',\n",
    "'Party Affiliation',\n",
    "'Home Heating Fuel - Other',\n",
    "'Relgion',\n",
    "'Ancestry',\n",
    "'Party Affiliation',\n",
    "'Medicinal',\n",
    "'Home Heating Fuel - Electricity',\n",
    "'Home Heating Fuel - Wood',\n",
    "'Home Structure',\n",
    "'Population',\n",
    "'Number of Rooms in Home',\n",
    "'Home Heating Fuel - Oil',\n",
    "'Employment Industry',\n",
    "'Religion',\n",
    "'Home Heating Fuel - Oil',\n",
    "'Ancestry',\n",
    "'Party Affiliation',\n",
    "'Home Vacancy Rate',\n",
    "'Housing Costs',\n",
    "'Population',\n",
    "'Employment Industry',\n",
    "'Housing Costs',\n",
    "'Party Affiliation',\n",
    "'Home Heating Fuel - Oil',\n",
    "'Ancestry',\n",
    "'Home Heating Fuel - Wood',\n",
    "'Home Heating Fuel - Electricity',\n",
    "'Number of Rooms in Home',\n",
    "'Medicinal',\n",
    "'Employment Industry',\n",
    "'Ancestry'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-01T16:56:03.321072Z",
     "start_time": "2020-01-01T16:56:03.143775Z"
    }
   },
   "outputs": [],
   "source": [
    "counts,values = pd.Series(feat).value_counts().values, pd.Series(feat).value_counts().index\n",
    "df_feat = pd.DataFrame(list(zip(values,counts)),columns=[\"value\",\"count\"])\n",
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-01T21:44:43.441012Z",
     "start_time": "2020-01-01T21:44:41.628205Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.bar(df_feat, x='value', y='count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "214.219px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
